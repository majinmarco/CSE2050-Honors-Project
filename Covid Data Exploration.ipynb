{
 "cells": [
  {
   "source": [
    "Notes on plotly dash, what I'd like to do\n",
    "* Slider for time\n",
    "* Search filter, synchronous between map and graph components\n",
    "* US map option\n",
    "* Possibly having a forecast graph under the normal one\n",
    "* If this is successful, create a dashboard connected to an API? (Make it separately of course)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intellectual-class",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    ObservationDate Province/State  Country/Region      Last Update  \\\n",
       "SNo                                                                   \n",
       "1        01/22/2020          Anhui  Mainland China  1/22/2020 17:00   \n",
       "2        01/22/2020        Beijing  Mainland China  1/22/2020 17:00   \n",
       "3        01/22/2020      Chongqing  Mainland China  1/22/2020 17:00   \n",
       "4        01/22/2020         Fujian  Mainland China  1/22/2020 17:00   \n",
       "5        01/22/2020          Gansu  Mainland China  1/22/2020 17:00   \n",
       "\n",
       "     Confirmed  Deaths  Recovered  \n",
       "SNo                                \n",
       "1          1.0     0.0        0.0  \n",
       "2         14.0     0.0        0.0  \n",
       "3          6.0     0.0        0.0  \n",
       "4          1.0     0.0        0.0  \n",
       "5          0.0     0.0        0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ObservationDate</th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n    </tr>\n    <tr>\n      <th>SNo</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>01/22/2020</td>\n      <td>Anhui</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/22/2020</td>\n      <td>Beijing</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/22/2020</td>\n      <td>Chongqing</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/22/2020</td>\n      <td>Fujian</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>01/22/2020</td>\n      <td>Gansu</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_normal = pd.read_csv(\"covid_dataset\\covid_19_data.csv\")\n",
    "\n",
    "# SNo is the index\n",
    "\n",
    "df_normal = df_normal.set_index(\"SNo\")\n",
    "df_normal.head()"
   ]
  },
  {
   "source": [
    "## Confirmed Cases Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  1/10/21  1/11/21  1/12/21  \\\n",
       "0        0        0        0        0  ...    53489    53538    53584   \n",
       "1        0        0        0        0  ...    63595    63971    64627   \n",
       "2        0        0        0        0  ...   102144   102369   102641   \n",
       "3        0        0        0        0  ...     8586     8586     8682   \n",
       "4        0        0        0        0  ...    18193    18254    18343   \n",
       "\n",
       "   1/13/21  1/14/21  1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0    53584    53775    53831    53938    53984    54062    54141  \n",
       "1    65334    65994    66635    67216    67690    67982    68568  \n",
       "2   102860   103127   103381   103611   103833   104092   104341  \n",
       "3     8818     8868     8946     9038     9083     9083     9194  \n",
       "4    18425    18613    18679    18765    18875    18926    19011  \n",
       "\n",
       "[5 rows x 368 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>1/22/20</th>\n      <th>1/23/20</th>\n      <th>1/24/20</th>\n      <th>1/25/20</th>\n      <th>1/26/20</th>\n      <th>1/27/20</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>33.93911</td>\n      <td>67.709953</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>53489</td>\n      <td>53538</td>\n      <td>53584</td>\n      <td>53584</td>\n      <td>53775</td>\n      <td>53831</td>\n      <td>53938</td>\n      <td>53984</td>\n      <td>54062</td>\n      <td>54141</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>Albania</td>\n      <td>41.15330</td>\n      <td>20.168300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>63595</td>\n      <td>63971</td>\n      <td>64627</td>\n      <td>65334</td>\n      <td>65994</td>\n      <td>66635</td>\n      <td>67216</td>\n      <td>67690</td>\n      <td>67982</td>\n      <td>68568</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>Algeria</td>\n      <td>28.03390</td>\n      <td>1.659600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>102144</td>\n      <td>102369</td>\n      <td>102641</td>\n      <td>102860</td>\n      <td>103127</td>\n      <td>103381</td>\n      <td>103611</td>\n      <td>103833</td>\n      <td>104092</td>\n      <td>104341</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>Andorra</td>\n      <td>42.50630</td>\n      <td>1.521800</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>8586</td>\n      <td>8586</td>\n      <td>8682</td>\n      <td>8818</td>\n      <td>8868</td>\n      <td>8946</td>\n      <td>9038</td>\n      <td>9083</td>\n      <td>9083</td>\n      <td>9194</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Angola</td>\n      <td>-11.20270</td>\n      <td>17.873900</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>18193</td>\n      <td>18254</td>\n      <td>18343</td>\n      <td>18425</td>\n      <td>18613</td>\n      <td>18679</td>\n      <td>18765</td>\n      <td>18875</td>\n      <td>18926</td>\n      <td>19011</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 368 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df_time_confirmed = pd.read_csv(\"covid_dataset\\\\time_series_covid_19_confirmed.csv\")\n",
    "df_time_confirmed.head()\n",
    "\n",
    "# This dataset shows daily levels of confirmed cases per location through longitude and latitude"
   ]
  },
  {
   "source": [
    "## US Confirmed Cases Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 1/10/21  1/11/21  1/12/21  1/13/21  1/14/21  \\\n",
       "0  32.539527 -86.644082  ...    4879     4902     4970     4998     5075   \n",
       "1  30.727750 -87.722071  ...   15327    15417    15572    15701    15841   \n",
       "2  31.868263 -85.387129  ...    1658     1663     1679     1685     1696   \n",
       "3  32.996421 -87.125115  ...    2051     2060     2090     2109     2113   \n",
       "4  33.982109 -86.567906  ...    5066     5080     5134     5170     5219   \n",
       "\n",
       "   1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0     5103     5154     5184     5198     5227  \n",
       "1    16002    16176    16251    16346    16513  \n",
       "2     1712     1723     1729     1730     1738  \n",
       "3     2130     2144     2151     2162     2170  \n",
       "4     5264     5292     5304     5308     5320  \n",
       "\n",
       "[5 rows x 375 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UID</th>\n      <th>iso2</th>\n      <th>iso3</th>\n      <th>code3</th>\n      <th>FIPS</th>\n      <th>Admin2</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Lat</th>\n      <th>Long_</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84001001</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1001.0</td>\n      <td>Autauga</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>32.539527</td>\n      <td>-86.644082</td>\n      <td>...</td>\n      <td>4879</td>\n      <td>4902</td>\n      <td>4970</td>\n      <td>4998</td>\n      <td>5075</td>\n      <td>5103</td>\n      <td>5154</td>\n      <td>5184</td>\n      <td>5198</td>\n      <td>5227</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84001003</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1003.0</td>\n      <td>Baldwin</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>30.727750</td>\n      <td>-87.722071</td>\n      <td>...</td>\n      <td>15327</td>\n      <td>15417</td>\n      <td>15572</td>\n      <td>15701</td>\n      <td>15841</td>\n      <td>16002</td>\n      <td>16176</td>\n      <td>16251</td>\n      <td>16346</td>\n      <td>16513</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84001005</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1005.0</td>\n      <td>Barbour</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>31.868263</td>\n      <td>-85.387129</td>\n      <td>...</td>\n      <td>1658</td>\n      <td>1663</td>\n      <td>1679</td>\n      <td>1685</td>\n      <td>1696</td>\n      <td>1712</td>\n      <td>1723</td>\n      <td>1729</td>\n      <td>1730</td>\n      <td>1738</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84001007</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1007.0</td>\n      <td>Bibb</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>32.996421</td>\n      <td>-87.125115</td>\n      <td>...</td>\n      <td>2051</td>\n      <td>2060</td>\n      <td>2090</td>\n      <td>2109</td>\n      <td>2113</td>\n      <td>2130</td>\n      <td>2144</td>\n      <td>2151</td>\n      <td>2162</td>\n      <td>2170</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84001009</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1009.0</td>\n      <td>Blount</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>33.982109</td>\n      <td>-86.567906</td>\n      <td>...</td>\n      <td>5066</td>\n      <td>5080</td>\n      <td>5134</td>\n      <td>5170</td>\n      <td>5219</td>\n      <td>5264</td>\n      <td>5292</td>\n      <td>5304</td>\n      <td>5308</td>\n      <td>5320</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 375 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_time_confirmed_US = pd.read_csv(\"covid_dataset\\\\time_series_covid_19_confirmed_US.csv\")\n",
    "df_time_confirmed_US.head()\n",
    "\n",
    "# This dataset shows daily levels of confirmed cases per location through longitude and latitude\n",
    "# What is UID, code3 and FIPS?"
   ]
  },
  {
   "source": [
    "## Deaths Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  1/10/21  1/11/21  1/12/21  \\\n",
       "0        0        0        0        0  ...     2277     2288     2301   \n",
       "1        0        0        0        0  ...     1241     1247     1252   \n",
       "2        0        0        0        0  ...     2807     2812     2816   \n",
       "3        0        0        0        0  ...       85       85       86   \n",
       "4        0        0        0        0  ...      416      420      422   \n",
       "\n",
       "   1/13/21  1/14/21  1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0     2301     2314     2324     2336     2339     2343     2346  \n",
       "1     1256     1261     1265     1270     1277     1281     1287  \n",
       "2     2819     2822     2827     2831     2836     2840     2843  \n",
       "3       87       88       88       91       91       91       92  \n",
       "4      424      425      428      431      436      439      442  \n",
       "\n",
       "[5 rows x 368 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>1/22/20</th>\n      <th>1/23/20</th>\n      <th>1/24/20</th>\n      <th>1/25/20</th>\n      <th>1/26/20</th>\n      <th>1/27/20</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>33.93911</td>\n      <td>67.709953</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2277</td>\n      <td>2288</td>\n      <td>2301</td>\n      <td>2301</td>\n      <td>2314</td>\n      <td>2324</td>\n      <td>2336</td>\n      <td>2339</td>\n      <td>2343</td>\n      <td>2346</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>Albania</td>\n      <td>41.15330</td>\n      <td>20.168300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1241</td>\n      <td>1247</td>\n      <td>1252</td>\n      <td>1256</td>\n      <td>1261</td>\n      <td>1265</td>\n      <td>1270</td>\n      <td>1277</td>\n      <td>1281</td>\n      <td>1287</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>Algeria</td>\n      <td>28.03390</td>\n      <td>1.659600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2807</td>\n      <td>2812</td>\n      <td>2816</td>\n      <td>2819</td>\n      <td>2822</td>\n      <td>2827</td>\n      <td>2831</td>\n      <td>2836</td>\n      <td>2840</td>\n      <td>2843</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>Andorra</td>\n      <td>42.50630</td>\n      <td>1.521800</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>85</td>\n      <td>85</td>\n      <td>86</td>\n      <td>87</td>\n      <td>88</td>\n      <td>88</td>\n      <td>91</td>\n      <td>91</td>\n      <td>91</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Angola</td>\n      <td>-11.20270</td>\n      <td>17.873900</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>416</td>\n      <td>420</td>\n      <td>422</td>\n      <td>424</td>\n      <td>425</td>\n      <td>428</td>\n      <td>431</td>\n      <td>436</td>\n      <td>439</td>\n      <td>442</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 368 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_time_deaths = pd.read_csv(\"covid_dataset\\\\time_series_covid_19_deaths.csv\")\n",
    "df_time_deaths.head()\n",
    "\n",
    "# Covid deaths per day in different locations correlating to longitude and latitude"
   ]
  },
  {
   "source": [
    "## US Deaths Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 1/10/21  1/11/21  1/12/21  1/13/21  1/14/21  \\\n",
       "0  32.539527 -86.644082  ...      54       55       55       55       55   \n",
       "1  30.727750 -87.722071  ...     173      173      175      175      177   \n",
       "2  31.868263 -85.387129  ...      35       35       35       35       36   \n",
       "3  32.996421 -87.125115  ...      48       48       48       48       47   \n",
       "4  33.982109 -86.567906  ...      77       77       79       80       80   \n",
       "\n",
       "   1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0       55       55       55       55       55  \n",
       "1      179      182      182      182      183  \n",
       "2       36       36       36       36       36  \n",
       "3       47       47       47       47       47  \n",
       "4       83       83       83       83       83  \n",
       "\n",
       "[5 rows x 376 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UID</th>\n      <th>iso2</th>\n      <th>iso3</th>\n      <th>code3</th>\n      <th>FIPS</th>\n      <th>Admin2</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Lat</th>\n      <th>Long_</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84001001</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1001.0</td>\n      <td>Autauga</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>32.539527</td>\n      <td>-86.644082</td>\n      <td>...</td>\n      <td>54</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84001003</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1003.0</td>\n      <td>Baldwin</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>30.727750</td>\n      <td>-87.722071</td>\n      <td>...</td>\n      <td>173</td>\n      <td>173</td>\n      <td>175</td>\n      <td>175</td>\n      <td>177</td>\n      <td>179</td>\n      <td>182</td>\n      <td>182</td>\n      <td>182</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84001005</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1005.0</td>\n      <td>Barbour</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>31.868263</td>\n      <td>-85.387129</td>\n      <td>...</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84001007</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1007.0</td>\n      <td>Bibb</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>32.996421</td>\n      <td>-87.125115</td>\n      <td>...</td>\n      <td>48</td>\n      <td>48</td>\n      <td>48</td>\n      <td>48</td>\n      <td>47</td>\n      <td>47</td>\n      <td>47</td>\n      <td>47</td>\n      <td>47</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84001009</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1009.0</td>\n      <td>Blount</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>33.982109</td>\n      <td>-86.567906</td>\n      <td>...</td>\n      <td>77</td>\n      <td>77</td>\n      <td>79</td>\n      <td>80</td>\n      <td>80</td>\n      <td>83</td>\n      <td>83</td>\n      <td>83</td>\n      <td>83</td>\n      <td>83</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 376 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_time_deaths_US = pd.read_csv(\"covid_dataset\\\\time_series_covid_19_deaths_US.csv\")\n",
    "df_time_deaths_US.head()\n",
    "\n",
    "# Covid deaths in the USA per day\n",
    "# Shows population, could provide good insights but which?"
   ]
  },
  {
   "source": [
    "## Recovered Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  1/10/21  1/11/21  1/12/21  \\\n",
       "0        0        0        0        0  ...    43948    44137    44608   \n",
       "1        0        0        0        0  ...    37648    37981    38421   \n",
       "2        0        0        0        0  ...    69212    69403    69608   \n",
       "3        0        0        0        0  ...     7724     7724     7930   \n",
       "4        0        0        0        0  ...    13872    14825    15512   \n",
       "\n",
       "   1/13/21  1/14/21  1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0    44850    45298    45434    45465    45868    46359    46554  \n",
       "1    38860    39246    39625    40090    40453    40870    41464  \n",
       "2    69791    69992    70188    70373    70554    70747    70933  \n",
       "3     8070     8091     8116     8116     8154     8154     8349  \n",
       "4    15631    16008    16120    16225    16347    16677    16822  \n",
       "\n",
       "[5 rows x 368 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>1/22/20</th>\n      <th>1/23/20</th>\n      <th>1/24/20</th>\n      <th>1/25/20</th>\n      <th>1/26/20</th>\n      <th>1/27/20</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>33.93911</td>\n      <td>67.709953</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>43948</td>\n      <td>44137</td>\n      <td>44608</td>\n      <td>44850</td>\n      <td>45298</td>\n      <td>45434</td>\n      <td>45465</td>\n      <td>45868</td>\n      <td>46359</td>\n      <td>46554</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>Albania</td>\n      <td>41.15330</td>\n      <td>20.168300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>37648</td>\n      <td>37981</td>\n      <td>38421</td>\n      <td>38860</td>\n      <td>39246</td>\n      <td>39625</td>\n      <td>40090</td>\n      <td>40453</td>\n      <td>40870</td>\n      <td>41464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>Algeria</td>\n      <td>28.03390</td>\n      <td>1.659600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>69212</td>\n      <td>69403</td>\n      <td>69608</td>\n      <td>69791</td>\n      <td>69992</td>\n      <td>70188</td>\n      <td>70373</td>\n      <td>70554</td>\n      <td>70747</td>\n      <td>70933</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>Andorra</td>\n      <td>42.50630</td>\n      <td>1.521800</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7724</td>\n      <td>7724</td>\n      <td>7930</td>\n      <td>8070</td>\n      <td>8091</td>\n      <td>8116</td>\n      <td>8116</td>\n      <td>8154</td>\n      <td>8154</td>\n      <td>8349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Angola</td>\n      <td>-11.20270</td>\n      <td>17.873900</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>13872</td>\n      <td>14825</td>\n      <td>15512</td>\n      <td>15631</td>\n      <td>16008</td>\n      <td>16120</td>\n      <td>16225</td>\n      <td>16347</td>\n      <td>16677</td>\n      <td>16822</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 368 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_time_recovered = pd.read_csv(\"covid_dataset\\\\time_series_covid_19_recovered.csv\")\n",
    "df_time_recovered.head()\n",
    "\n",
    "# Recovered people per day with long/lat"
   ]
  },
  {
   "source": [
    "* Get rid of NaN\n",
    "* Can I group countries and/or provinces together? \n",
    "* Do the time series csv's have data points overtime?\n",
    "* Ratio of dead vs recovered?\n",
    "* Recovery rate overtime?\n",
    "* Covid Circle Map- normal one without time series, then one with time series on plotly dash that can be changed by slider to see growth overtime\n",
    "    * Other possible features for dashboard:\n",
    "    * Search function for filtering?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Getting rid of/replacing NaN values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/5/2021\n",
    "# TODO- Get rid of NaN values, unnecessary columns"
   ]
  },
  {
   "source": [
    "### DF Normal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ObservationDate      Province/State  Country/Region  \\\n",
       "SNo                                                          \n",
       "0                  NaN                 NaN             NaN   \n",
       "1           01/22/2020               Anhui  Mainland China   \n",
       "2           01/22/2020             Beijing  Mainland China   \n",
       "3           01/22/2020           Chongqing  Mainland China   \n",
       "4           01/22/2020              Fujian  Mainland China   \n",
       "...                ...                 ...             ...   \n",
       "205946      01/19/2021  Zakarpattia Oblast         Ukraine   \n",
       "205947      01/19/2021   Zaporizhia Oblast         Ukraine   \n",
       "205948      01/19/2021             Zeeland     Netherlands   \n",
       "205949      01/19/2021            Zhejiang  Mainland China   \n",
       "205950      01/19/2021     Zhytomyr Oblast         Ukraine   \n",
       "\n",
       "                Last Update  Confirmed  Deaths  Recovered  \n",
       "SNo                                                        \n",
       "0                       NaN        NaN     NaN        NaN  \n",
       "1           1/22/2020 17:00        1.0     0.0        0.0  \n",
       "2           1/22/2020 17:00       14.0     0.0        0.0  \n",
       "3           1/22/2020 17:00        6.0     0.0        0.0  \n",
       "4           1/22/2020 17:00        1.0     0.0        0.0  \n",
       "...                     ...        ...     ...        ...  \n",
       "205946  2021-01-20 05:21:54    29957.0   689.0    26661.0  \n",
       "205947  2021-01-20 05:21:54    62492.0   738.0    39168.0  \n",
       "205948  2021-01-20 05:21:54    13031.0   149.0        0.0  \n",
       "205949  2021-01-20 05:21:54     1316.0     1.0     1298.0  \n",
       "205950  2021-01-20 05:21:54    42758.0   707.0    37834.0  \n",
       "\n",
       "[205951 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ObservationDate</th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Last Update</th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n    </tr>\n    <tr>\n      <th>SNo</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/22/2020</td>\n      <td>Anhui</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/22/2020</td>\n      <td>Beijing</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/22/2020</td>\n      <td>Chongqing</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/22/2020</td>\n      <td>Fujian</td>\n      <td>Mainland China</td>\n      <td>1/22/2020 17:00</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>205946</th>\n      <td>01/19/2021</td>\n      <td>Zakarpattia Oblast</td>\n      <td>Ukraine</td>\n      <td>2021-01-20 05:21:54</td>\n      <td>29957.0</td>\n      <td>689.0</td>\n      <td>26661.0</td>\n    </tr>\n    <tr>\n      <th>205947</th>\n      <td>01/19/2021</td>\n      <td>Zaporizhia Oblast</td>\n      <td>Ukraine</td>\n      <td>2021-01-20 05:21:54</td>\n      <td>62492.0</td>\n      <td>738.0</td>\n      <td>39168.0</td>\n    </tr>\n    <tr>\n      <th>205948</th>\n      <td>01/19/2021</td>\n      <td>Zeeland</td>\n      <td>Netherlands</td>\n      <td>2021-01-20 05:21:54</td>\n      <td>13031.0</td>\n      <td>149.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>205949</th>\n      <td>01/19/2021</td>\n      <td>Zhejiang</td>\n      <td>Mainland China</td>\n      <td>2021-01-20 05:21:54</td>\n      <td>1316.0</td>\n      <td>1.0</td>\n      <td>1298.0</td>\n    </tr>\n    <tr>\n      <th>205950</th>\n      <td>01/19/2021</td>\n      <td>Zhytomyr Oblast</td>\n      <td>Ukraine</td>\n      <td>2021-01-20 05:21:54</td>\n      <td>42758.0</td>\n      <td>707.0</td>\n      <td>37834.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>205951 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# First, let's see what columns have NaN values\n",
    "df_normal_NaN = df_normal[df_normal.isna().any(axis=1)]\n",
    "df_normal_NaN\n",
    "count = len(df_normal[df_normal['Province/State'].isna()].index) # Gets amount of rows with NaN in this column\n",
    "print(count == len(df_normal.index)) # False, therefore not all Province/State Values are Nan, let's replace them\n",
    "\n",
    "df_normal['Province/State'] = df_normal['Province/State'].fillna('N/A')\n",
    "\n",
    "df_normal_NaN = df_normal[df_normal.isna().any(axis=1)]\n",
    "df_normal_NaN\n",
    "\n",
    "df_normal.reindex(range(len(df_normal)))\n",
    "\n",
    "# State/Province was the only series with null values. Let's move on to the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Confirmed     Deaths   Recovered\n",
       "ObservationDate                                   \n",
       "01/01/2021       84025713.0  1827732.0  47289078.0\n",
       "01/02/2021       84649404.0  1835910.0  47595212.0\n",
       "01/03/2021       85183607.0  1843211.0  47860306.0\n",
       "01/04/2021       85734208.0  1853501.0  48148226.0\n",
       "01/05/2021       86469506.0  1868909.0  48464481.0\n",
       "...                     ...        ...         ...\n",
       "12/27/2020       80856030.0  1765126.0  45698093.0\n",
       "12/28/2020       81349247.0  1774686.0  45994203.0\n",
       "12/29/2020       82008964.0  1790140.0  46348935.0\n",
       "12/30/2020       82768267.0  1805232.0  46731568.0\n",
       "12/31/2020       83488443.0  1818336.0  47010049.0\n",
       "\n",
       "[364 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Confirmed</th>\n      <th>Deaths</th>\n      <th>Recovered</th>\n    </tr>\n    <tr>\n      <th>ObservationDate</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>01/01/2021</th>\n      <td>84025713.0</td>\n      <td>1827732.0</td>\n      <td>47289078.0</td>\n    </tr>\n    <tr>\n      <th>01/02/2021</th>\n      <td>84649404.0</td>\n      <td>1835910.0</td>\n      <td>47595212.0</td>\n    </tr>\n    <tr>\n      <th>01/03/2021</th>\n      <td>85183607.0</td>\n      <td>1843211.0</td>\n      <td>47860306.0</td>\n    </tr>\n    <tr>\n      <th>01/04/2021</th>\n      <td>85734208.0</td>\n      <td>1853501.0</td>\n      <td>48148226.0</td>\n    </tr>\n    <tr>\n      <th>01/05/2021</th>\n      <td>86469506.0</td>\n      <td>1868909.0</td>\n      <td>48464481.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12/27/2020</th>\n      <td>80856030.0</td>\n      <td>1765126.0</td>\n      <td>45698093.0</td>\n    </tr>\n    <tr>\n      <th>12/28/2020</th>\n      <td>81349247.0</td>\n      <td>1774686.0</td>\n      <td>45994203.0</td>\n    </tr>\n    <tr>\n      <th>12/29/2020</th>\n      <td>82008964.0</td>\n      <td>1790140.0</td>\n      <td>46348935.0</td>\n    </tr>\n    <tr>\n      <th>12/30/2020</th>\n      <td>82768267.0</td>\n      <td>1805232.0</td>\n      <td>46731568.0</td>\n    </tr>\n    <tr>\n      <th>12/31/2020</th>\n      <td>83488443.0</td>\n      <td>1818336.0</td>\n      <td>47010049.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>364 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# I also just noticed how this dataset is structured, so I want to make a new dataframe that is the sum of the observation dates. Also I want to drop the first index because it is all NaN values (DONE)\n",
    "\n",
    "df_normal_simple = df_normal[['ObservationDate', 'Confirmed', 'Deaths', 'Recovered']].set_index(df_normal.index)\n",
    "\n",
    "df_normal_simple\n",
    "\n",
    "#df_normal_simple.groupby(by='ObservationDate').sum()\n",
    "#df_normal_simple.groupby(by='ObservationDate').sum().sort_values(by='ObservationDate', ascending=False)\n",
    "\n",
    "# datetime.strptime(date_string, format)\n",
    "# format = '%m/%d/%y'\n",
    "\n",
    "#test = df_normal.iloc[0]['ObservationDate']\n",
    "#test\n",
    "#test = datetime.strptime(test, '%m/%d/%Y')\n",
    "#test (works)\n",
    "\n",
    "pd.to_datetime(df_normal_simple['ObservationDate'])\n",
    "#df_normal_simple.groupby(by='ObservationDate').sum()\n",
    "#df_normal_simple = df_normal_simple.groupby(by='ObservationDate').sum().sort_values(by='ObservationDate')\n",
    "\n",
    "df_normal_simple.groupby('ObservationDate').agg({'Confirmed':'sum', 'Deaths':'sum', 'Recovered':'sum'}).sort_index()\n",
    "\n",
    "#df_temp = df_normal_simple[df_normal_simple['ObservationDate'].year == 2021]"
   ]
  },
  {
   "source": [
    "### Confirmed Case Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Country/Region        Lat        Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0           Afghanistan  33.939110   67.709953        0        0        0   \n",
       "1               Albania  41.153300   20.168300        0        0        0   \n",
       "2               Algeria  28.033900    1.659600        0        0        0   \n",
       "3               Andorra  42.506300    1.521800        0        0        0   \n",
       "4                Angola -11.202700   17.873900        0        0        0   \n",
       "..                  ...        ...         ...      ...      ...      ...   \n",
       "267             Vietnam  14.058324  108.277199        0        2        2   \n",
       "268  West Bank and Gaza  31.952200   35.233200        0        0        0   \n",
       "269               Yemen  15.552727   48.516388        0        0        0   \n",
       "270              Zambia -13.133897   27.849332        0        0        0   \n",
       "271            Zimbabwe -19.015438   29.154857        0        0        0   \n",
       "\n",
       "     1/25/20  1/26/20  1/27/20  1/28/20  ...  1/10/21  1/11/21  1/12/21  \\\n",
       "0          0        0        0        0  ...    53489    53538    53584   \n",
       "1          0        0        0        0  ...    63595    63971    64627   \n",
       "2          0        0        0        0  ...   102144   102369   102641   \n",
       "3          0        0        0        0  ...     8586     8586     8682   \n",
       "4          0        0        0        0  ...    18193    18254    18343   \n",
       "..       ...      ...      ...      ...  ...      ...      ...      ...   \n",
       "267        2        2        2        2  ...     1514     1515     1520   \n",
       "268        0        0        0        0  ...   147400   148171   148968   \n",
       "269        0        0        0        0  ...     2104     2105     2107   \n",
       "270        0        0        0        0  ...    27728    28596    29757   \n",
       "271        0        0        0        0  ...    21477    22297    23239   \n",
       "\n",
       "     1/13/21  1/14/21  1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0      53584    53775    53831    53938    53984    54062    54141  \n",
       "1      65334    65994    66635    67216    67690    67982    68568  \n",
       "2     102860   103127   103381   103611   103833   104092   104341  \n",
       "3       8818     8868     8946     9038     9083     9083     9194  \n",
       "4      18425    18613    18679    18765    18875    18926    19011  \n",
       "..       ...      ...      ...      ...      ...      ...      ...  \n",
       "267     1521     1531     1536     1537     1537     1539     1540  \n",
       "268   149769   150505   151142   151569   152031   152555   153093  \n",
       "269     2109     2110     2111     2112     2112     2113     2115  \n",
       "270    31100    32800    34278    36074    37605    38207    39515  \n",
       "271    24256    25368    26109    26881    27203    27892    28675  \n",
       "\n",
       "[272 rows x 367 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>1/22/20</th>\n      <th>1/23/20</th>\n      <th>1/24/20</th>\n      <th>1/25/20</th>\n      <th>1/26/20</th>\n      <th>1/27/20</th>\n      <th>1/28/20</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>33.939110</td>\n      <td>67.709953</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>53489</td>\n      <td>53538</td>\n      <td>53584</td>\n      <td>53584</td>\n      <td>53775</td>\n      <td>53831</td>\n      <td>53938</td>\n      <td>53984</td>\n      <td>54062</td>\n      <td>54141</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>41.153300</td>\n      <td>20.168300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>63595</td>\n      <td>63971</td>\n      <td>64627</td>\n      <td>65334</td>\n      <td>65994</td>\n      <td>66635</td>\n      <td>67216</td>\n      <td>67690</td>\n      <td>67982</td>\n      <td>68568</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>28.033900</td>\n      <td>1.659600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>102144</td>\n      <td>102369</td>\n      <td>102641</td>\n      <td>102860</td>\n      <td>103127</td>\n      <td>103381</td>\n      <td>103611</td>\n      <td>103833</td>\n      <td>104092</td>\n      <td>104341</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Andorra</td>\n      <td>42.506300</td>\n      <td>1.521800</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>8586</td>\n      <td>8586</td>\n      <td>8682</td>\n      <td>8818</td>\n      <td>8868</td>\n      <td>8946</td>\n      <td>9038</td>\n      <td>9083</td>\n      <td>9083</td>\n      <td>9194</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Angola</td>\n      <td>-11.202700</td>\n      <td>17.873900</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>18193</td>\n      <td>18254</td>\n      <td>18343</td>\n      <td>18425</td>\n      <td>18613</td>\n      <td>18679</td>\n      <td>18765</td>\n      <td>18875</td>\n      <td>18926</td>\n      <td>19011</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>Vietnam</td>\n      <td>14.058324</td>\n      <td>108.277199</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1514</td>\n      <td>1515</td>\n      <td>1520</td>\n      <td>1521</td>\n      <td>1531</td>\n      <td>1536</td>\n      <td>1537</td>\n      <td>1537</td>\n      <td>1539</td>\n      <td>1540</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>West Bank and Gaza</td>\n      <td>31.952200</td>\n      <td>35.233200</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>147400</td>\n      <td>148171</td>\n      <td>148968</td>\n      <td>149769</td>\n      <td>150505</td>\n      <td>151142</td>\n      <td>151569</td>\n      <td>152031</td>\n      <td>152555</td>\n      <td>153093</td>\n    </tr>\n    <tr>\n      <th>269</th>\n      <td>Yemen</td>\n      <td>15.552727</td>\n      <td>48.516388</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2104</td>\n      <td>2105</td>\n      <td>2107</td>\n      <td>2109</td>\n      <td>2110</td>\n      <td>2111</td>\n      <td>2112</td>\n      <td>2112</td>\n      <td>2113</td>\n      <td>2115</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>Zambia</td>\n      <td>-13.133897</td>\n      <td>27.849332</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>27728</td>\n      <td>28596</td>\n      <td>29757</td>\n      <td>31100</td>\n      <td>32800</td>\n      <td>34278</td>\n      <td>36074</td>\n      <td>37605</td>\n      <td>38207</td>\n      <td>39515</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>Zimbabwe</td>\n      <td>-19.015438</td>\n      <td>29.154857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>21477</td>\n      <td>22297</td>\n      <td>23239</td>\n      <td>24256</td>\n      <td>25368</td>\n      <td>26109</td>\n      <td>26881</td>\n      <td>27203</td>\n      <td>27892</td>\n      <td>28675</td>\n    </tr>\n  </tbody>\n</table>\n<p>272 rows × 367 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_time_confirmed_NaN = df_time_confirmed[df_time_confirmed.isna().any(axis=1)]\n",
    "df_time_confirmed_NaN\n",
    "#print(df_time_confirmed.shape) # This number indicates to us that the only column with null values is, again 'Province/State'\n",
    "\n",
    "df_time_confirmed['Province/State'] = df_time_confirmed['Province/State'].fillna('N/A')\n",
    "df_time_confirmed_NaN = df_time_confirmed[df_time_confirmed.isna().any(axis=1)]\n",
    "df_time_confirmed_NaN # Only gives us a single row that contains data not important for our case. Lets delete this row (52, 'Repatriated Travellers')\n",
    "\n",
    "#df_time_confirmed = df_time_confirmed.drop(52)\n",
    "#df_time_confirmed_NaN = df_time_confirmed[df_time_confirmed.isna().any(axis=1)]\n",
    "df_time_confirmed_NaN\n",
    "\n",
    "# Also want to add a combined_key column like US Time Series has\n",
    "\n",
    "# del df_time_confirmed['Combined_Key'] # Already done\n",
    "del df_time_confirmed['Province/State']\n",
    "df_time_confirmed.reindex(range(len(df_time_confirmed)))"
   ]
  },
  {
   "source": [
    "### Confirmed Case USA Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_confirmed_US_NaN = df_time_confirmed_US[df_time_confirmed_US.isna().any(axis=1)]\n",
    "df_time_confirmed_US_NaN # This df is providing too much info that we won't need in general, so let's delete UID, iso2, iso3, code3, and FIPS. We will keep Admin 2 because it would probably give us good data in terms of precision\n",
    "\n",
    "df_time_confirmed_US.drop('UID', axis=1, inplace=True) # inplace is used to not have to redefine df_time_confirmed_US\n",
    "df_time_confirmed_US.drop('iso2', axis=1, inplace=True) # axis = 1 is for columns, axis = 0 is for rows\n",
    "df_time_confirmed_US.drop('iso3', axis=1, inplace=True) \n",
    "df_time_confirmed_US.drop('code3', axis=1, inplace=True) \n",
    "df_time_confirmed_US.drop('FIPS', axis=1, inplace=True) \n",
    "# Error because it's already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Admin2, Province_State, Country_Region, Lat, Long_, Combined_Key, 1/22/20, 1/23/20, 1/24/20, 1/25/20, 1/26/20, 1/27/20, 1/28/20, 1/29/20, 1/30/20, 1/31/20, 2/1/20, 2/2/20, 2/3/20, 2/4/20, 2/5/20, 2/6/20, 2/7/20, 2/8/20, 2/9/20, 2/10/20, 2/11/20, 2/12/20, 2/13/20, 2/14/20, 2/15/20, 2/16/20, 2/17/20, 2/18/20, 2/19/20, 2/20/20, 2/21/20, 2/22/20, 2/23/20, 2/24/20, 2/25/20, 2/26/20, 2/27/20, 2/28/20, 2/29/20, 3/1/20, 3/2/20, 3/3/20, 3/4/20, 3/5/20, 3/6/20, 3/7/20, 3/8/20, 3/9/20, 3/10/20, 3/11/20, 3/12/20, 3/13/20, 3/14/20, 3/15/20, 3/16/20, 3/17/20, 3/18/20, 3/19/20, 3/20/20, 3/21/20, 3/22/20, 3/23/20, 3/24/20, 3/25/20, 3/26/20, 3/27/20, 3/28/20, 3/29/20, 3/30/20, 3/31/20, 4/1/20, 4/2/20, 4/3/20, 4/4/20, 4/5/20, 4/6/20, 4/7/20, 4/8/20, 4/9/20, 4/10/20, 4/11/20, 4/12/20, 4/13/20, 4/14/20, 4/15/20, 4/16/20, 4/17/20, 4/18/20, 4/19/20, 4/20/20, 4/21/20, 4/22/20, 4/23/20, 4/24/20, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 370 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Admin2</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Lat</th>\n      <th>Long_</th>\n      <th>Combined_Key</th>\n      <th>1/22/20</th>\n      <th>1/23/20</th>\n      <th>1/24/20</th>\n      <th>1/25/20</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 370 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_time_confirmed_US['Province_State'] = df_time_confirmed_US['Province_State'].fillna('N/A')\n",
    "df_time_confirmed_US['Admin2'] = df_time_confirmed_US['Admin2'].fillna('N/A')\n",
    "df_time_confirmed_US_NaN = df_time_confirmed_US[df_time_confirmed_US.isna().any(axis=1)]\n",
    "df_time_confirmed_US_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           State Province/State Country/Region        Lat        Long  \\\n",
       "0        Autauga        Alabama             US  32.539527  -86.644082   \n",
       "1        Baldwin        Alabama             US  30.727750  -87.722071   \n",
       "2        Barbour        Alabama             US  31.868263  -85.387129   \n",
       "3           Bibb        Alabama             US  32.996421  -87.125115   \n",
       "4         Blount        Alabama             US  33.982109  -86.567906   \n",
       "...          ...            ...            ...        ...         ...   \n",
       "3334  Sweetwater        Wyoming             US  41.659439 -108.882788   \n",
       "3335       Teton        Wyoming             US  43.935225 -110.589080   \n",
       "3336       Uinta        Wyoming             US  41.287818 -110.547578   \n",
       "3338    Washakie        Wyoming             US  43.904516 -107.680187   \n",
       "3339      Weston        Wyoming             US  43.839612 -104.567488   \n",
       "\n",
       "                 Combined_Key  1/22/20  1/23/20  1/24/20  1/25/20  ...  \\\n",
       "0        Autauga, Alabama, US        0        0        0        0  ...   \n",
       "1        Baldwin, Alabama, US        0        0        0        0  ...   \n",
       "2        Barbour, Alabama, US        0        0        0        0  ...   \n",
       "3           Bibb, Alabama, US        0        0        0        0  ...   \n",
       "4         Blount, Alabama, US        0        0        0        0  ...   \n",
       "...                       ...      ...      ...      ...      ...  ...   \n",
       "3334  Sweetwater, Wyoming, US        0        0        0        0  ...   \n",
       "3335       Teton, Wyoming, US        0        0        0        0  ...   \n",
       "3336       Uinta, Wyoming, US        0        0        0        0  ...   \n",
       "3338    Washakie, Wyoming, US        0        0        0        0  ...   \n",
       "3339      Weston, Wyoming, US        0        0        0        0  ...   \n",
       "\n",
       "      1/10/21  1/11/21  1/12/21  1/13/21  1/14/21  1/15/21  1/16/21  1/17/21  \\\n",
       "0        4879     4902     4970     4998     5075     5103     5154     5184   \n",
       "1       15327    15417    15572    15701    15841    16002    16176    16251   \n",
       "2        1658     1663     1679     1685     1696     1712     1723     1729   \n",
       "3        2051     2060     2090     2109     2113     2130     2144     2151   \n",
       "4        5066     5080     5134     5170     5219     5264     5292     5304   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3334     3162     3187     3210     3222     3250     3262     3280     3290   \n",
       "3335     2353     2447     2497     2502     2579     2605     2614     2685   \n",
       "3336     1708     1744     1764     1774     1794     1806     1813     1817   \n",
       "3338      805      817      825      830      837      840      842      843   \n",
       "3339      485      485      601      601      602      602      602      602   \n",
       "\n",
       "      1/18/21  1/19/21  \n",
       "0        5198     5227  \n",
       "1       16346    16513  \n",
       "2        1730     1738  \n",
       "3        2162     2170  \n",
       "4        5308     5320  \n",
       "...       ...      ...  \n",
       "3334     3312     3329  \n",
       "3335     2753     2769  \n",
       "3336     1833     1843  \n",
       "3338      844      846  \n",
       "3339      602      606  \n",
       "\n",
       "[3232 rows x 370 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>Province/State</th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>Combined_Key</th>\n      <th>1/22/20</th>\n      <th>1/23/20</th>\n      <th>1/24/20</th>\n      <th>1/25/20</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Autauga</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>32.539527</td>\n      <td>-86.644082</td>\n      <td>Autauga, Alabama, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4879</td>\n      <td>4902</td>\n      <td>4970</td>\n      <td>4998</td>\n      <td>5075</td>\n      <td>5103</td>\n      <td>5154</td>\n      <td>5184</td>\n      <td>5198</td>\n      <td>5227</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Baldwin</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>30.727750</td>\n      <td>-87.722071</td>\n      <td>Baldwin, Alabama, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>15327</td>\n      <td>15417</td>\n      <td>15572</td>\n      <td>15701</td>\n      <td>15841</td>\n      <td>16002</td>\n      <td>16176</td>\n      <td>16251</td>\n      <td>16346</td>\n      <td>16513</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Barbour</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>31.868263</td>\n      <td>-85.387129</td>\n      <td>Barbour, Alabama, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1658</td>\n      <td>1663</td>\n      <td>1679</td>\n      <td>1685</td>\n      <td>1696</td>\n      <td>1712</td>\n      <td>1723</td>\n      <td>1729</td>\n      <td>1730</td>\n      <td>1738</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bibb</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>32.996421</td>\n      <td>-87.125115</td>\n      <td>Bibb, Alabama, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2051</td>\n      <td>2060</td>\n      <td>2090</td>\n      <td>2109</td>\n      <td>2113</td>\n      <td>2130</td>\n      <td>2144</td>\n      <td>2151</td>\n      <td>2162</td>\n      <td>2170</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Blount</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>33.982109</td>\n      <td>-86.567906</td>\n      <td>Blount, Alabama, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>5066</td>\n      <td>5080</td>\n      <td>5134</td>\n      <td>5170</td>\n      <td>5219</td>\n      <td>5264</td>\n      <td>5292</td>\n      <td>5304</td>\n      <td>5308</td>\n      <td>5320</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3334</th>\n      <td>Sweetwater</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>41.659439</td>\n      <td>-108.882788</td>\n      <td>Sweetwater, Wyoming, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3162</td>\n      <td>3187</td>\n      <td>3210</td>\n      <td>3222</td>\n      <td>3250</td>\n      <td>3262</td>\n      <td>3280</td>\n      <td>3290</td>\n      <td>3312</td>\n      <td>3329</td>\n    </tr>\n    <tr>\n      <th>3335</th>\n      <td>Teton</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>43.935225</td>\n      <td>-110.589080</td>\n      <td>Teton, Wyoming, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2353</td>\n      <td>2447</td>\n      <td>2497</td>\n      <td>2502</td>\n      <td>2579</td>\n      <td>2605</td>\n      <td>2614</td>\n      <td>2685</td>\n      <td>2753</td>\n      <td>2769</td>\n    </tr>\n    <tr>\n      <th>3336</th>\n      <td>Uinta</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>41.287818</td>\n      <td>-110.547578</td>\n      <td>Uinta, Wyoming, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1708</td>\n      <td>1744</td>\n      <td>1764</td>\n      <td>1774</td>\n      <td>1794</td>\n      <td>1806</td>\n      <td>1813</td>\n      <td>1817</td>\n      <td>1833</td>\n      <td>1843</td>\n    </tr>\n    <tr>\n      <th>3338</th>\n      <td>Washakie</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>43.904516</td>\n      <td>-107.680187</td>\n      <td>Washakie, Wyoming, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>805</td>\n      <td>817</td>\n      <td>825</td>\n      <td>830</td>\n      <td>837</td>\n      <td>840</td>\n      <td>842</td>\n      <td>843</td>\n      <td>844</td>\n      <td>846</td>\n    </tr>\n    <tr>\n      <th>3339</th>\n      <td>Weston</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>43.839612</td>\n      <td>-104.567488</td>\n      <td>Weston, Wyoming, US</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>485</td>\n      <td>485</td>\n      <td>601</td>\n      <td>601</td>\n      <td>602</td>\n      <td>602</td>\n      <td>602</td>\n      <td>602</td>\n      <td>602</td>\n      <td>606</td>\n    </tr>\n  </tbody>\n</table>\n<p>3232 rows × 370 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# I also observed that this time series includes miscellanious locations, such as cruises, which have latitude and longitude as 0. Let's delete those. Let's also Rename Long_ to Long and Combined_Key to State_Country\n",
    "\n",
    "df_time_confirmed_US.rename(columns={'Long_': 'Long', \n",
    "                                     'State_Country': 'Combined_Key', \n",
    "                                     'Province_State' : 'Province/State', \n",
    "                                     'Country_Region' : 'Country/Region', \n",
    "                                     'State' : 'City'}, \n",
    "                                     inplace = True)\n",
    "\n",
    "# df_filtered = df_time_confirmed_US[df_time_confirmed_US['Long'] != 0 and df_time_confirmed['Lat'] != 0]\n",
    "# Getting problems with statement above, have to check what datatype long and lat are, because they don't seem to be numbers\n",
    "\n",
    "# df_time_confirmed_US.dtypes # They're floats...\n",
    "# Edit: turns out I was doing it wrong the whole time...\n",
    "\n",
    "df_filtered = df_time_confirmed_US[(df_time_confirmed_US['Long'] != 0.0) & (df_time_confirmed_US['Lat'] != 0.0)]\n",
    "df_filtered\n",
    "\n",
    "df_time_confirmed_US = df_filtered #Done\n",
    "df_time_confirmed_US.rename(columns={'Admin2':'State'}, inplace=True)\n",
    "df_time_confirmed_US\n"
   ]
  },
  {
   "source": [
    "### Confirmed Deaths Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Country/Region        Lat        Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0           Afghanistan  33.939110   67.709953        0        0        0   \n",
       "1               Albania  41.153300   20.168300        0        0        0   \n",
       "2               Algeria  28.033900    1.659600        0        0        0   \n",
       "3               Andorra  42.506300    1.521800        0        0        0   \n",
       "4                Angola -11.202700   17.873900        0        0        0   \n",
       "..                  ...        ...         ...      ...      ...      ...   \n",
       "267             Vietnam  14.058324  108.277199        0        0        0   \n",
       "268  West Bank and Gaza  31.952200   35.233200        0        0        0   \n",
       "269               Yemen  15.552727   48.516388        0        0        0   \n",
       "270              Zambia -13.133897   27.849332        0        0        0   \n",
       "271            Zimbabwe -19.015438   29.154857        0        0        0   \n",
       "\n",
       "     1/25/20  1/26/20  1/27/20  1/28/20  ...  1/10/21  1/11/21  1/12/21  \\\n",
       "0          0        0        0        0  ...     2277     2288     2301   \n",
       "1          0        0        0        0  ...     1241     1247     1252   \n",
       "2          0        0        0        0  ...     2807     2812     2816   \n",
       "3          0        0        0        0  ...       85       85       86   \n",
       "4          0        0        0        0  ...      416      420      422   \n",
       "..       ...      ...      ...      ...  ...      ...      ...      ...   \n",
       "267        0        0        0        0  ...       35       35       35   \n",
       "268        0        0        0        0  ...     1604     1614     1630   \n",
       "269        0        0        0        0  ...      611      612      612   \n",
       "270        0        0        0        0  ...      469      471      495   \n",
       "271        0        0        0        0  ...      507      528      551   \n",
       "\n",
       "     1/13/21  1/14/21  1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0       2301     2314     2324     2336     2339     2343     2346  \n",
       "1       1256     1261     1265     1270     1277     1281     1287  \n",
       "2       2819     2822     2827     2831     2836     2840     2843  \n",
       "3         87       88       88       91       91       91       92  \n",
       "4        424      425      428      431      436      439      442  \n",
       "..       ...      ...      ...      ...      ...      ...      ...  \n",
       "267       35       35       35       35       35       35       35  \n",
       "268     1658     1665     1687     1700     1718     1726     1741  \n",
       "269      612      612      612      612      612      612      612  \n",
       "270      509      514      527      537      546      559      578  \n",
       "271      589      636      666      683      713      773      825  \n",
       "\n",
       "[268 rows x 367 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>1/22/20</th>\n      <th>1/23/20</th>\n      <th>1/24/20</th>\n      <th>1/25/20</th>\n      <th>1/26/20</th>\n      <th>1/27/20</th>\n      <th>1/28/20</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>33.939110</td>\n      <td>67.709953</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2277</td>\n      <td>2288</td>\n      <td>2301</td>\n      <td>2301</td>\n      <td>2314</td>\n      <td>2324</td>\n      <td>2336</td>\n      <td>2339</td>\n      <td>2343</td>\n      <td>2346</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>41.153300</td>\n      <td>20.168300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1241</td>\n      <td>1247</td>\n      <td>1252</td>\n      <td>1256</td>\n      <td>1261</td>\n      <td>1265</td>\n      <td>1270</td>\n      <td>1277</td>\n      <td>1281</td>\n      <td>1287</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>28.033900</td>\n      <td>1.659600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2807</td>\n      <td>2812</td>\n      <td>2816</td>\n      <td>2819</td>\n      <td>2822</td>\n      <td>2827</td>\n      <td>2831</td>\n      <td>2836</td>\n      <td>2840</td>\n      <td>2843</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Andorra</td>\n      <td>42.506300</td>\n      <td>1.521800</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>85</td>\n      <td>85</td>\n      <td>86</td>\n      <td>87</td>\n      <td>88</td>\n      <td>88</td>\n      <td>91</td>\n      <td>91</td>\n      <td>91</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Angola</td>\n      <td>-11.202700</td>\n      <td>17.873900</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>416</td>\n      <td>420</td>\n      <td>422</td>\n      <td>424</td>\n      <td>425</td>\n      <td>428</td>\n      <td>431</td>\n      <td>436</td>\n      <td>439</td>\n      <td>442</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>Vietnam</td>\n      <td>14.058324</td>\n      <td>108.277199</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>West Bank and Gaza</td>\n      <td>31.952200</td>\n      <td>35.233200</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1604</td>\n      <td>1614</td>\n      <td>1630</td>\n      <td>1658</td>\n      <td>1665</td>\n      <td>1687</td>\n      <td>1700</td>\n      <td>1718</td>\n      <td>1726</td>\n      <td>1741</td>\n    </tr>\n    <tr>\n      <th>269</th>\n      <td>Yemen</td>\n      <td>15.552727</td>\n      <td>48.516388</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>611</td>\n      <td>612</td>\n      <td>612</td>\n      <td>612</td>\n      <td>612</td>\n      <td>612</td>\n      <td>612</td>\n      <td>612</td>\n      <td>612</td>\n      <td>612</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>Zambia</td>\n      <td>-13.133897</td>\n      <td>27.849332</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>469</td>\n      <td>471</td>\n      <td>495</td>\n      <td>509</td>\n      <td>514</td>\n      <td>527</td>\n      <td>537</td>\n      <td>546</td>\n      <td>559</td>\n      <td>578</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>Zimbabwe</td>\n      <td>-19.015438</td>\n      <td>29.154857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>507</td>\n      <td>528</td>\n      <td>551</td>\n      <td>589</td>\n      <td>636</td>\n      <td>666</td>\n      <td>683</td>\n      <td>713</td>\n      <td>773</td>\n      <td>825</td>\n    </tr>\n  </tbody>\n</table>\n<p>268 rows × 367 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df_time_deaths = pd.read_csv(\"covid_dataset\\\\time_series_covid_19_deaths.csv\")\n",
    "\n",
    "df_time_deaths_NaN = df_time_deaths[df_time_deaths.isna().any(axis=1)]\n",
    "df_time_deaths_NaN\n",
    "\n",
    "del df_time_deaths['Province/State']\n",
    "\n",
    "df_filtered = df_time_deaths[(df_time_deaths['Long'] != 0.0) & (df_time_deaths['Lat'] != 0.0)]\n",
    "df_filtered\n",
    "\n",
    "df_time_deaths = df_filtered\n",
    "df_time_deaths"
   ]
  },
  {
   "source": [
    "### Confirmed USA Deaths Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           UID iso2 iso3  code3     FIPS        City    State Country/Region  \\\n",
       "0     84001001   US  USA    840   1001.0     Autauga  Alabama             US   \n",
       "1     84001003   US  USA    840   1003.0     Baldwin  Alabama             US   \n",
       "2     84001005   US  USA    840   1005.0     Barbour  Alabama             US   \n",
       "3     84001007   US  USA    840   1007.0        Bibb  Alabama             US   \n",
       "4     84001009   US  USA    840   1009.0      Blount  Alabama             US   \n",
       "...        ...  ...  ...    ...      ...         ...      ...            ...   \n",
       "3334  84056037   US  USA    840  56037.0  Sweetwater  Wyoming             US   \n",
       "3335  84056039   US  USA    840  56039.0       Teton  Wyoming             US   \n",
       "3336  84056041   US  USA    840  56041.0       Uinta  Wyoming             US   \n",
       "3338  84056043   US  USA    840  56043.0    Washakie  Wyoming             US   \n",
       "3339  84056045   US  USA    840  56045.0      Weston  Wyoming             US   \n",
       "\n",
       "            Lat        Long  ... 1/10/21  1/11/21  1/12/21  1/13/21  1/14/21  \\\n",
       "0     32.539527  -86.644082  ...      54       55       55       55       55   \n",
       "1     30.727750  -87.722071  ...     173      173      175      175      177   \n",
       "2     31.868263  -85.387129  ...      35       35       35       35       36   \n",
       "3     32.996421  -87.125115  ...      48       48       48       48       47   \n",
       "4     33.982109  -86.567906  ...      77       77       79       80       80   \n",
       "...         ...         ...  ...     ...      ...      ...      ...      ...   \n",
       "3334  41.659439 -108.882788  ...      24       24       26       26       26   \n",
       "3335  43.935225 -110.589080  ...       4        4        4        4        4   \n",
       "3336  41.287818 -110.547578  ...       8        8        9        9        9   \n",
       "3338  43.904516 -107.680187  ...      21       21       23       23       23   \n",
       "3339  43.839612 -104.567488  ...       4        4        4        4        4   \n",
       "\n",
       "      1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0          55       55       55       55       55  \n",
       "1         179      182      182      182      183  \n",
       "2          36       36       36       36       36  \n",
       "3          47       47       47       47       47  \n",
       "4          83       83       83       83       83  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "3334       26       26       26       26       28  \n",
       "3335        4        4        4        4        5  \n",
       "3336        9        9        9        9       10  \n",
       "3338       23       23       23       23       24  \n",
       "3339        4        4        4        4        4  \n",
       "\n",
       "[3232 rows x 376 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UID</th>\n      <th>iso2</th>\n      <th>iso3</th>\n      <th>code3</th>\n      <th>FIPS</th>\n      <th>City</th>\n      <th>State</th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84001001</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1001.0</td>\n      <td>Autauga</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>32.539527</td>\n      <td>-86.644082</td>\n      <td>...</td>\n      <td>54</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84001003</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1003.0</td>\n      <td>Baldwin</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>30.727750</td>\n      <td>-87.722071</td>\n      <td>...</td>\n      <td>173</td>\n      <td>173</td>\n      <td>175</td>\n      <td>175</td>\n      <td>177</td>\n      <td>179</td>\n      <td>182</td>\n      <td>182</td>\n      <td>182</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84001005</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1005.0</td>\n      <td>Barbour</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>31.868263</td>\n      <td>-85.387129</td>\n      <td>...</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>35</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84001007</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1007.0</td>\n      <td>Bibb</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>32.996421</td>\n      <td>-87.125115</td>\n      <td>...</td>\n      <td>48</td>\n      <td>48</td>\n      <td>48</td>\n      <td>48</td>\n      <td>47</td>\n      <td>47</td>\n      <td>47</td>\n      <td>47</td>\n      <td>47</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84001009</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>1009.0</td>\n      <td>Blount</td>\n      <td>Alabama</td>\n      <td>US</td>\n      <td>33.982109</td>\n      <td>-86.567906</td>\n      <td>...</td>\n      <td>77</td>\n      <td>77</td>\n      <td>79</td>\n      <td>80</td>\n      <td>80</td>\n      <td>83</td>\n      <td>83</td>\n      <td>83</td>\n      <td>83</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3334</th>\n      <td>84056037</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>56037.0</td>\n      <td>Sweetwater</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>41.659439</td>\n      <td>-108.882788</td>\n      <td>...</td>\n      <td>24</td>\n      <td>24</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>26</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>3335</th>\n      <td>84056039</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>56039.0</td>\n      <td>Teton</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>43.935225</td>\n      <td>-110.589080</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3336</th>\n      <td>84056041</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>56041.0</td>\n      <td>Uinta</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>41.287818</td>\n      <td>-110.547578</td>\n      <td>...</td>\n      <td>8</td>\n      <td>8</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3338</th>\n      <td>84056043</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>56043.0</td>\n      <td>Washakie</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>43.904516</td>\n      <td>-107.680187</td>\n      <td>...</td>\n      <td>21</td>\n      <td>21</td>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3339</th>\n      <td>84056045</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>56045.0</td>\n      <td>Weston</td>\n      <td>Wyoming</td>\n      <td>US</td>\n      <td>43.839612</td>\n      <td>-104.567488</td>\n      <td>...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>3232 rows × 376 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df_time_deaths_US_NaN = df_time_deaths_US[df_time_deaths_US.isna().any(axis=1)]\n",
    "df_time_deaths_US_NaN\n",
    "\n",
    "#df_time_deaths_US.drop('UID', axis=1, inplace=True) # inplace is used to not have to redefine df_time_confirmed_US\n",
    "#df_time_deaths_US.drop('iso2', axis=1, inplace=True) # axis = 1 is for columns, axis = 0 is for rows\n",
    "#df_time_deaths_US.drop('iso3', axis=1, inplace=True) \n",
    "#df_time_deaths_US.drop('code3', axis=1, inplace=True) \n",
    "#df_time_deaths_US.drop('FIPS', axis=1, inplace=True)\n",
    "\n",
    "#df_time_deaths_US['Province_State'] = df_time_deaths_US['Province_State'].fillna('N/A')\n",
    "#df_time_deaths_US['Admin2'] = df_time_deaths_US['Admin2'].fillna('N/A')\n",
    "#df_time_deaths_US_NaN = df_time_deaths_US[df_time_deaths_US.isna().any(axis=1)]\n",
    "#df_time_deaths_US_NaN\n",
    "\n",
    "df_time_deaths_US.rename(columns={'Long_': 'Long', \n",
    "                                     'State_Country': 'Combined_Key', \n",
    "                                     'Province_State' : 'State', \n",
    "                                     'Country_Region' : 'Country/Region', \n",
    "                                     'Admin2' : 'City'}, \n",
    "                                     inplace = True)\n",
    "\n",
    "df_filtered = df_time_deaths_US[(df_time_deaths_US['Long'] != 0.0) & (df_time_deaths_US['Lat'] != 0.0)]\n",
    "df_filtered\n",
    "\n",
    "df_time_deaths_US = df_filtered #Done\n",
    "df_time_deaths_US"
   ]
  },
  {
   "source": [
    "### US Recovered Time Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Country/Region        Lat        Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0           Afghanistan  33.939110   67.709953        0        0        0   \n",
       "1               Albania  41.153300   20.168300        0        0        0   \n",
       "2               Algeria  28.033900    1.659600        0        0        0   \n",
       "3               Andorra  42.506300    1.521800        0        0        0   \n",
       "4                Angola -11.202700   17.873900        0        0        0   \n",
       "..                  ...        ...         ...      ...      ...      ...   \n",
       "252             Vietnam  14.058324  108.277199        0        0        0   \n",
       "253  West Bank and Gaza  31.952200   35.233200        0        0        0   \n",
       "254               Yemen  15.552727   48.516388        0        0        0   \n",
       "255              Zambia -13.133897   27.849332        0        0        0   \n",
       "256            Zimbabwe -19.015438   29.154857        0        0        0   \n",
       "\n",
       "     1/25/20  1/26/20  1/27/20  1/28/20  ...  1/10/21  1/11/21  1/12/21  \\\n",
       "0          0        0        0        0  ...    43948    44137    44608   \n",
       "1          0        0        0        0  ...    37648    37981    38421   \n",
       "2          0        0        0        0  ...    69212    69403    69608   \n",
       "3          0        0        0        0  ...     7724     7724     7930   \n",
       "4          0        0        0        0  ...    13872    14825    15512   \n",
       "..       ...      ...      ...      ...  ...      ...      ...      ...   \n",
       "252        0        0        0        0  ...     1361     1361     1361   \n",
       "253        0        0        0        0  ...   131117   132158   133599   \n",
       "254        0        0        0        0  ...     1407     1416     1416   \n",
       "255        0        0        0        0  ...    20598    20781    21074   \n",
       "256        0        0        0        0  ...    12582    13213    13396   \n",
       "\n",
       "     1/13/21  1/14/21  1/15/21  1/16/21  1/17/21  1/18/21  1/19/21  \n",
       "0      44850    45298    45434    45465    45868    46359    46554  \n",
       "1      38860    39246    39625    40090    40453    40870    41464  \n",
       "2      69791    69992    70188    70373    70554    70747    70933  \n",
       "3       8070     8091     8116     8116     8154     8154     8349  \n",
       "4      15631    16008    16120    16225    16347    16677    16822  \n",
       "..       ...      ...      ...      ...      ...      ...      ...  \n",
       "252     1369     1369     1380     1380     1380     1402     1402  \n",
       "253   134977   136247   137648   138495   139131   140075   140914  \n",
       "254     1419     1419     1419     1419     1419     1421     1422  \n",
       "255    21568    22504    24105    25106    26159    27327    28066  \n",
       "256    13658    14714    15414    15872    16512    17372    18110  \n",
       "\n",
       "[255 rows x 367 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country/Region</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>1/22/20</th>\n      <th>1/23/20</th>\n      <th>1/24/20</th>\n      <th>1/25/20</th>\n      <th>1/26/20</th>\n      <th>1/27/20</th>\n      <th>1/28/20</th>\n      <th>...</th>\n      <th>1/10/21</th>\n      <th>1/11/21</th>\n      <th>1/12/21</th>\n      <th>1/13/21</th>\n      <th>1/14/21</th>\n      <th>1/15/21</th>\n      <th>1/16/21</th>\n      <th>1/17/21</th>\n      <th>1/18/21</th>\n      <th>1/19/21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>33.939110</td>\n      <td>67.709953</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>43948</td>\n      <td>44137</td>\n      <td>44608</td>\n      <td>44850</td>\n      <td>45298</td>\n      <td>45434</td>\n      <td>45465</td>\n      <td>45868</td>\n      <td>46359</td>\n      <td>46554</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>41.153300</td>\n      <td>20.168300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>37648</td>\n      <td>37981</td>\n      <td>38421</td>\n      <td>38860</td>\n      <td>39246</td>\n      <td>39625</td>\n      <td>40090</td>\n      <td>40453</td>\n      <td>40870</td>\n      <td>41464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>28.033900</td>\n      <td>1.659600</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>69212</td>\n      <td>69403</td>\n      <td>69608</td>\n      <td>69791</td>\n      <td>69992</td>\n      <td>70188</td>\n      <td>70373</td>\n      <td>70554</td>\n      <td>70747</td>\n      <td>70933</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Andorra</td>\n      <td>42.506300</td>\n      <td>1.521800</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7724</td>\n      <td>7724</td>\n      <td>7930</td>\n      <td>8070</td>\n      <td>8091</td>\n      <td>8116</td>\n      <td>8116</td>\n      <td>8154</td>\n      <td>8154</td>\n      <td>8349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Angola</td>\n      <td>-11.202700</td>\n      <td>17.873900</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>13872</td>\n      <td>14825</td>\n      <td>15512</td>\n      <td>15631</td>\n      <td>16008</td>\n      <td>16120</td>\n      <td>16225</td>\n      <td>16347</td>\n      <td>16677</td>\n      <td>16822</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>Vietnam</td>\n      <td>14.058324</td>\n      <td>108.277199</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1361</td>\n      <td>1361</td>\n      <td>1361</td>\n      <td>1369</td>\n      <td>1369</td>\n      <td>1380</td>\n      <td>1380</td>\n      <td>1380</td>\n      <td>1402</td>\n      <td>1402</td>\n    </tr>\n    <tr>\n      <th>253</th>\n      <td>West Bank and Gaza</td>\n      <td>31.952200</td>\n      <td>35.233200</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>131117</td>\n      <td>132158</td>\n      <td>133599</td>\n      <td>134977</td>\n      <td>136247</td>\n      <td>137648</td>\n      <td>138495</td>\n      <td>139131</td>\n      <td>140075</td>\n      <td>140914</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>Yemen</td>\n      <td>15.552727</td>\n      <td>48.516388</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1407</td>\n      <td>1416</td>\n      <td>1416</td>\n      <td>1419</td>\n      <td>1419</td>\n      <td>1419</td>\n      <td>1419</td>\n      <td>1419</td>\n      <td>1421</td>\n      <td>1422</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>Zambia</td>\n      <td>-13.133897</td>\n      <td>27.849332</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>20598</td>\n      <td>20781</td>\n      <td>21074</td>\n      <td>21568</td>\n      <td>22504</td>\n      <td>24105</td>\n      <td>25106</td>\n      <td>26159</td>\n      <td>27327</td>\n      <td>28066</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>Zimbabwe</td>\n      <td>-19.015438</td>\n      <td>29.154857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>12582</td>\n      <td>13213</td>\n      <td>13396</td>\n      <td>13658</td>\n      <td>14714</td>\n      <td>15414</td>\n      <td>15872</td>\n      <td>16512</td>\n      <td>17372</td>\n      <td>18110</td>\n    </tr>\n  </tbody>\n</table>\n<p>255 rows × 367 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df_time_recovered_NaN = df_time_recovered[df_time_recovered.isna().any(axis=1)]\n",
    "df_time_recovered_NaN\n",
    "\n",
    "del df_time_recovered['Province/State']\n",
    "\n",
    "df_filtered = df_time_recovered[(df_time_recovered['Long'] != 0.0) & (df_time_recovered['Lat'] != 0.0)]\n",
    "df_filtered\n",
    "\n",
    "df_time_recovered = df_filtered #Done\n",
    "df_time_recovered"
   ]
  },
  {
   "source": [
    "# __From here on out, we're done with the data cleaning! Now to visualize!__"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO- figure out how to graph time series and normal dataframe with plotly, see what you can do, create function to filter visualization by country, state, etc.\n",
    "# TODO- figure out how to visualize earth on plotly, start with whole planet magnitude thing; then we could try US map. View notes on top for more info/ideas\n",
    "# Use df_normal for normal visualizations, for dashboard use all timeseries; make a US map and a global map\n",
    "\n",
    "# Important note- df_normal will not be used today, needs extra work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "filter() missing 2 required positional arguments: 'df' and 'title'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d9d5317cb934>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Afghanistan'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;31m# Fuck yeah, noticed that this is not confirmed per day though, let's do that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: filter() missing 2 required positional arguments: 'df' and 'title'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import datetime as datetime\n",
    "\n",
    "# TODO convert column names to series, convert the values in that series to datetime types\n",
    "# DONE\n",
    "\n",
    "def filter(country, df, title):\n",
    "\n",
    "    # [IGNORE] I deleted the province/region column, so this is necessary because territories are included and have bee proved problematic for the function\n",
    "    df=df.groupby(by='Country/Region').sum()\n",
    "\n",
    "    if country not in df.index:\n",
    "        print(\"Country data not found. Try again.\")\n",
    "    \n",
    "    else:\n",
    "        column_list = df.columns.tolist()\n",
    "\n",
    "        column_list = column_list[2:]\n",
    "        dates = []\n",
    "\n",
    "        for i in column_list:\n",
    "            dates.append(pd.to_datetime(i))\n",
    "\n",
    "        dates_series = pd.Series(dates)\n",
    "\n",
    "        confirmed_series = df.loc[country]\n",
    "        confirmed_series = confirmed_series.drop(['Lat','Long'])\n",
    "\n",
    "        fig = px.line(x = dates_series, y=confirmed_series)\n",
    "        fig.update_xaxes(title=\"Date\")\n",
    "        fig.update_yaxes(title=\"Daily Numbers\")\n",
    "        fig.update_layout(title={\"text\":title})\n",
    "        fig.show()\n",
    "\n",
    "filter('Afghanistan')\n",
    "# Fuck yeah, noticed that this is not confirmed per day though, let's do that\n",
    "\n",
    "def filter_daily(country, df, title=None):\n",
    "    \n",
    "    #I deleted the province/region column, so this is necessary because territories are included and have bee proved problematic for the function\n",
    "    df=df.groupby(by='Country/Region').sum()\n",
    "    \n",
    "    if country not in df.index:\n",
    "        print(\"Country data not found. Try again.\")\n",
    "\n",
    "    else:\n",
    "        column_list = df.columns.tolist()\n",
    "\n",
    "        column_list = column_list[2:]\n",
    "        dates = []\n",
    "\n",
    "        for i in column_list:\n",
    "            dates.append(pd.to_datetime(i))\n",
    "\n",
    "        dates_series = pd.Series(dates)\n",
    "\n",
    "        confirmed_series = df.loc[country]\n",
    "        confirmed_series = confirmed_series.drop(['Lat','Long'])\n",
    "\n",
    "        for i in range(confirmed_series.shape[0]-1, 0, -1):\n",
    "            if i == 0:\n",
    "                break\n",
    "            else:\n",
    "                confirmed_series.iloc[i] = confirmed_series.iloc[i]-confirmed_series.iloc[i-1]\n",
    "        \n",
    "        fig = px.line(x = dates_series, y=confirmed_series)\n",
    "        fig.update_xaxes(title=\"Date\")\n",
    "        fig.update_yaxes(title=\"Daily Numbers\")\n",
    "        fig.update_layout(title={\"text\":title})\n",
    "        fig.show()\n",
    "\n",
    "filter('Bolivia', df_time_confirmed, \"Confirmed Cases\")\n",
    "\n",
    "#I deleted the province/region column, so modifications will have to be made to make the map actually work"
   ]
  },
  {
   "source": [
    "## Make US Graph Function to filter down to states"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'State'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a8472b471a68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m#filter_daily_US('all', df_time_confirmed_US)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m \u001b[0mfilter_daily_US\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_time_confirmed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Florida Filter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-a8472b471a68>\u001b[0m in \u001b[0;36mfilter_daily_US\u001b[1;34m(state, df, title)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Grouping by state, so let's add them up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'State'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Sum of confirmed daily cases country-wide\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   6712\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6714\u001b[1;33m         return DataFrameGroupBy(\n\u001b[0m\u001b[0;32m   6715\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6716\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[0;32m    561\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'State'"
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_US(state, df, title=None):\n",
    "\n",
    "    # Grouping by state, so let's add them up\n",
    "    df=df.groupby(by='State').sum()\n",
    "    \n",
    "    if state not in df.index:\n",
    "        print(\"State data not found. Try again.\")\n",
    "    \n",
    "    else:\n",
    "        column_list = df.columns.tolist()\n",
    "\n",
    "        dates = []\n",
    "\n",
    "        for i in column_list:\n",
    "            dates.append(pd.to_datetime(i))\n",
    "\n",
    "        dates_series = pd.Series(dates)\n",
    "\n",
    "        confirmed_series = df.loc[state]\n",
    "        confirmed_series = confirmed_series[5:]\n",
    "\n",
    "        fig = px.line(x = dates_series, y=confirmed_series)\n",
    "        fig.update_xaxes(title=\"Date\")\n",
    "        fig.update_yaxes(title=\"Daily Numbers\")\n",
    "        fig.update_layout(title={\"text\":title})\n",
    "        fig.show()\n",
    "\n",
    "def filter_daily_US(state, df, title=None):\n",
    "\n",
    "    # Grouping by state, so let's add them up\n",
    "    df=df.groupby(by='State').sum()\n",
    "\n",
    "    # Sum of confirmed daily cases country-wide\n",
    "    if state.lower() == 'all':\n",
    "        column_list = df.columns.tolist()\n",
    "\n",
    "        column_list = column_list[5:]\n",
    "        dates = []\n",
    "\n",
    "        for i in column_list:\n",
    "            dates.append(pd.to_datetime(i))\n",
    "\n",
    "        dates_series = pd.Series(dates)\n",
    "\n",
    "        confirmed_series = df[8:].sum(axis=0)\n",
    "\n",
    "        for i in range(confirmed_series.shape[0]-1, 0, -1):\n",
    "            if i == 0:\n",
    "                break\n",
    "            else:\n",
    "                confirmed_series.iloc[i] = confirmed_series.iloc[i]-confirmed_series.iloc[i-1]\n",
    "\n",
    "        print(dates_series)\n",
    "        print(confirmed_series)\n",
    "\n",
    "    elif state not in df.index:\n",
    "        print(\"State data not found. Try again.\")\n",
    "    \n",
    "    else:\n",
    "        column_list = df.columns.tolist()\n",
    "\n",
    "        column_list = column_list[5:]\n",
    "        dates = []\n",
    "\n",
    "        for i in column_list:\n",
    "            dates.append(pd.to_datetime(i))\n",
    "\n",
    "        dates_series = pd.Series(dates)\n",
    "\n",
    "        confirmed_series = df.loc[state]\n",
    "        confirmed_series = confirmed_series[5:]\n",
    "\n",
    "        for i in range(confirmed_series.shape[0]-1, 0, -1):\n",
    "            if i == 0:\n",
    "                break\n",
    "            else:\n",
    "                confirmed_series.iloc[i] = confirmed_series.iloc[i]-confirmed_series.iloc[i-1]\n",
    "\n",
    "    fig = px.line(x = dates_series, y=confirmed_series)\n",
    "    fig.update_xaxes(title=\"Date\")\n",
    "    fig.update_yaxes(title=\"Daily Numbers\")\n",
    "    fig.update_layout(title={\"text\":title})\n",
    "    fig.show()\n",
    "\n",
    "#filter_daily_US('all', df_time_confirmed_US)\n",
    "filter_daily_US('all', df_time_confirmed, 'Florida Filter')"
   ]
  },
  {
   "source": [
    "## Notes for 3/5/21-3/6/21 Grind\n",
    "* Great grind, learned a lot and we can build upon what we've made.\n",
    "* Make part of function that can allow you to see combined daily cases/combined cases\n",
    "* Should study how to make the map because it seems more complex.\n",
    "* Also, line charts could be built upon to have options of 3-day and 7-day averages.\n",
    "* How to make slider work with time series?\n",
    "* Also make a map that just shows the totals\n",
    "* I don't think the individual country and provinceare important, since there's long and lat we could just use the combined key.\n",
    "    * On this note, I think that I kinda fucked up the long, lat and the region columns so we may have to start anew on a blank slate if we want this to work correctly. We can work on the map in this notebook for now, though.\n",
    "\n",
    "FIRST TODO- RECREATE NOTEBOOK NEATLY\n",
    "\n",
    "TODO: Map, all states, countries functions; 'All' function (sum of cases globally or in USA)\n",
    "TODO after: start in a blank slate, fix df mess problems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0ce83d9b2a67bcc77f55859b04485f86f2de06272551e161694b74f8d76ef55f7",
   "display_name": "Python 3.8.5 32-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}